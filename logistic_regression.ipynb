{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87853d9c-4cdb-4b47-94a6-c4d8d515d093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC # Logistic Regression - Credit Default Prediction\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 1: Load Libraries and Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== Starting Logistic Regression Model ===\\n\")\n",
    "\n",
    "# Load the scaled data\n",
    "spark.sql(\"USE credit_risk\")\n",
    "df_spark = spark.table(\"application_train_scaled\")\n",
    "\n",
    "print(f\"Loaded data: {df_spark.count():,} rows Ã— {len(df_spark.columns)} columns\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 2: Convert to Pandas\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"Converting to Pandas (this may take 2-3 minutes)...\")\n",
    "df = df_spark.toPandas()\n",
    "\n",
    "print(f\"âœ… Converted to Pandas: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print()\n",
    "\n",
    "# Check for any missing values\n",
    "missing_count = df.isnull().sum().sum()\n",
    "print(f\"Missing values: {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(\"âš ï¸ WARNING: Missing values detected!\")\n",
    "else:\n",
    "    print(\"âœ… No missing values\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 3: Prepare Features and Target\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "# Remove ID column and target from features\n",
    "\n",
    "# Identify columns to exclude from features\n",
    "exclude_cols = ['SK_ID_CURR', 'TARGET']\n",
    "\n",
    "# Get feature columns\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Create feature matrix (X) and target vector (y)\n",
    "X = df[feature_cols]\n",
    "y = df['TARGET']\n",
    "\n",
    "print(f\"=== Data Preparation ===\")\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeature columns (first 20):\")\n",
    "for i, col in enumerate(feature_cols[:20], 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "if len(feature_cols) > 20:\n",
    "    print(f\"  ... and {len(feature_cols) - 20} more\")\n",
    "\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nClass balance:\")\n",
    "print(f\"  No Default (0): {(y == 0).sum():,} ({(y == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Default (1):    {(y == 1).sum():,} ({(y == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 4: Split Data into Train and Test Sets\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Split: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class balance in both sets\n",
    ")\n",
    "\n",
    "print(f\"=== Train/Test Split ===\")\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set:     {X_test.shape[0]:,} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nFeatures: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(f\"  No Default (0): {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Default (1):    {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(f\"  No Default (0): {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.2f}%)\")\n",
    "print(f\"  Default (1):    {(y_test == 1).sum():,} ({(y_test == 1).mean()*100:.2f}%)\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 5: Train Logistic Regression Model\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== Training Logistic Regression Model ===\\n\")\n",
    "print(\"This may take a few minutes with ~100 features and 245K training samples...\")\n",
    "\n",
    "# Initialize logistic regression\n",
    "# max_iter increased to ensure convergence with many features\n",
    "logreg = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',  # Good for large datasets\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training...\")\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Model training complete!\")\n",
    "print(f\"\\nModel converged: {logreg.n_iter_[0]} iterations\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 6: Make Predictions\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== Making Predictions ===\\n\")\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_train_pred_proba = logreg.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "y_test_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"âœ… Predictions complete\")\n",
    "print(f\"Training predictions: {len(y_train_pred):,}\")\n",
    "print(f\"Test predictions: {len(y_test_pred):,}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 7: Evaluate Model Performance\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training set performance\n",
    "print(\"\\nðŸ“Š TRAINING SET PERFORMANCE:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  F1 Score:  {f1_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_train, y_train_pred_proba):.4f}\")\n",
    "\n",
    "# Test set performance\n",
    "print(\"\\nðŸ“Š TEST SET PERFORMANCE:\")\n",
    "print(f\"  Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  F1 Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Metric Interpretations\n",
    "# MAGIC \n",
    "# MAGIC - **Accuracy**: Overall correctness - what % of predictions were correct\n",
    "# MAGIC - **Precision**: Of predicted defaults, what % actually defaulted (avoid false alarms)\n",
    "# MAGIC - **Recall**: Of actual defaults, what % did we catch (avoid missing defaults)\n",
    "# MAGIC - **F1 Score**: Balance between precision and recall\n",
    "# MAGIC - **ROC-AUC**: Overall model quality (0.5 = random, 1.0 = perfect)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 8: Confusion Matrix\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n=== CONFUSION MATRIX (Test Set) ===\\n\")\n",
    "print(\"                  Predicted\")\n",
    "print(\"                No Default  Default\")\n",
    "print(f\"Actual No Default   {cm[0,0]:6,}    {cm[0,1]:6,}\")\n",
    "print(f\"Actual Default      {cm[1,0]:6,}    {cm[1,1]:6,}\")\n",
    "\n",
    "print(\"\\nBreakdown:\")\n",
    "print(f\"  True Negatives (TN):  {cm[0,0]:,} - Correctly predicted no default\")\n",
    "print(f\"  False Positives (FP): {cm[0,1]:,} - Incorrectly predicted default\")\n",
    "print(f\"  False Negatives (FN): {cm[1,0]:,} - Missed actual defaults âš ï¸\")\n",
    "print(f\"  True Positives (TP):  {cm[1,1]:,} - Correctly predicted default\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Default', 'Default'],\n",
    "            yticklabels=['No Default', 'Default'])\n",
    "plt.title('Confusion Matrix - Test Set', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 9: ROC Curve\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier (AUC = 0.50)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“ˆ ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  â€¢ 0.50 = Random guessing (no predictive power)\")\n",
    "print(\"  â€¢ 0.70 = Acceptable model\")\n",
    "print(\"  â€¢ 0.80 = Good model\")\n",
    "print(\"  â€¢ 0.90 = Excellent model\")\n",
    "print(\"  â€¢ 1.00 = Perfect model\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 10: Classification Report\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n=== DETAILED CLASSIFICATION REPORT (Test Set) ===\\n\")\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                          target_names=['No Default (0)', 'Default (1)'],\n",
    "                          digits=4))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 11: Feature Importance Analysis\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== FEATURE IMPORTANCE ===\\n\")\n",
    "print(\"Analyzing which features are most predictive of default...\\n\")\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = logreg.coef_[0]\n",
    "\n",
    "# Create dataframe of feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': np.abs(coefficients)\n",
    "})\n",
    "\n",
    "# Sort by absolute value of coefficient (impact regardless of direction)\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "# Top 20 most important features\n",
    "print(\"ðŸ“Š TOP 20 MOST IMPORTANT FEATURES:\\n\")\n",
    "top_20 = feature_importance.head(20)\n",
    "\n",
    "for i, row in enumerate(top_20.itertuples(), 1):\n",
    "    direction = \"â†‘ Increases\" if row.coefficient > 0 else \"â†“ Decreases\"\n",
    "    print(f\"{i:2}. {row.feature:40} | Coef: {row.coefficient:8.4f} | {direction} default risk\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Visualize top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20_plot = feature_importance.head(20).sort_values('coefficient')\n",
    "colors = ['red' if x < 0 else 'green' for x in top_20_plot['coefficient']]\n",
    "\n",
    "plt.barh(range(len(top_20_plot)), top_20_plot['coefficient'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_20_plot)), top_20_plot['feature'])\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.title('Top 20 Most Important Features\\n(Red = Decreases Default Risk, Green = Increases Default Risk)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 12: Prediction Probability Distribution\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Plot distribution of predicted probabilities\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_test_pred_proba[y_test == 0], bins=50, alpha=0.7, label='Actual No Default', color='blue')\n",
    "plt.hist(y_test_pred_proba[y_test == 1], bins=50, alpha=0.7, label='Actual Default', color='red')\n",
    "plt.xlabel('Predicted Probability of Default', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.title('Distribution of Predicted Probabilities', fontsize=13, fontweight='bold')\n",
    "plt.axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold (0.5)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([y_test_pred_proba[y_test == 0], y_test_pred_proba[y_test == 1]], \n",
    "            labels=['Actual No Default', 'Actual Default'])\n",
    "plt.ylabel('Predicted Probability of Default', fontsize=11)\n",
    "plt.title('Predicted Probability by Actual Class', fontsize=13, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGood separation means:\")\n",
    "print(\"  â€¢ Blue (no default) concentrated near 0\")\n",
    "print(\"  â€¢ Red (default) concentrated near 1\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 13: Sample Predictions\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== SAMPLE PREDICTIONS ===\\n\")\n",
    "\n",
    "# Create sample predictions dataframe\n",
    "sample_predictions = pd.DataFrame({\n",
    "    'SK_ID_CURR': df.loc[X_test.index, 'SK_ID_CURR'].values,\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_test_pred,\n",
    "    'Probability_Default': y_test_pred_proba\n",
    "})\n",
    "\n",
    "# Show some correct predictions\n",
    "print(\"âœ… Correctly Predicted Defaults (first 10):\")\n",
    "correct_defaults = sample_predictions[(sample_predictions['Actual'] == 1) & \n",
    "                                     (sample_predictions['Predicted'] == 1)].head(10)\n",
    "print(correct_defaults.to_string(index=False))\n",
    "\n",
    "print(\"\\nâœ… Correctly Predicted No Defaults (first 10):\")\n",
    "correct_no_defaults = sample_predictions[(sample_predictions['Actual'] == 0) & \n",
    "                                         (sample_predictions['Predicted'] == 0)].head(10)\n",
    "print(correct_no_defaults.to_string(index=False))\n",
    "\n",
    "print(\"\\nâŒ Incorrectly Predicted (False Positives - first 10):\")\n",
    "false_positives = sample_predictions[(sample_predictions['Actual'] == 0) & \n",
    "                                    (sample_predictions['Predicted'] == 1)].head(10)\n",
    "print(false_positives.to_string(index=False))\n",
    "\n",
    "print(\"\\nâš ï¸ Missed Defaults (False Negatives - first 10):\")\n",
    "false_negatives = sample_predictions[(sample_predictions['Actual'] == 1) & \n",
    "                                    (sample_predictions['Predicted'] == 0)].head(10)\n",
    "print(false_negatives.to_string(index=False))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 14: Save Results (Skip Model Saving on Serverless)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== Saving Results ===\\n\")\n",
    "\n",
    "# Save feature importance to table instead\n",
    "feature_importance_spark = spark.createDataFrame(feature_importance)\n",
    "feature_importance_spark.write.mode(\"overwrite\").saveAsTable(\"credit_risk.feature_importance\")\n",
    "\n",
    "print(\"âœ… Feature importance saved to table: credit_risk.feature_importance\")\n",
    "\n",
    "# Save test predictions to table\n",
    "sample_predictions_spark = spark.createDataFrame(sample_predictions)\n",
    "sample_predictions_spark.write.mode(\"overwrite\").saveAsTable(\"credit_risk.test_predictions\")\n",
    "\n",
    "print(\"âœ… Test predictions saved to table: credit_risk.test_predictions\")\n",
    "\n",
    "print(\"\\nâš ï¸ Note: Model not saved (serverless compute limitation)\")\n",
    "print(\"   You can retrain the model anytime by running this notebook again\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Step 15: Final Summary\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset:\")\n",
    "print(f\"  â€¢ Total samples: {len(df):,}\")\n",
    "print(f\"  â€¢ Training samples: {len(X_train):,} (80%)\")\n",
    "print(f\"  â€¢ Test samples: {len(X_test):,} (20%)\")\n",
    "print(f\"  â€¢ Number of features: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Model Performance (Test Set):\")\n",
    "print(f\"  â€¢ Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  â€¢ Precision: {precision_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  â€¢ Recall:    {recall_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  â€¢ F1 Score:  {f1_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"  â€¢ ROC-AUC:   {roc_auc_score(y_test, y_test_pred_proba):.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ” Confusion Matrix (Test Set):\")\n",
    "print(f\"  â€¢ True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"  â€¢ False Positives: {cm[0,1]:,}\")\n",
    "print(f\"  â€¢ False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"  â€¢ True Positives:  {cm[1,1]:,}\")\n",
    "\n",
    "print(f\"\\nâ­ Top 3 Most Important Features:\")\n",
    "for i, row in enumerate(feature_importance.head(3).itertuples(), 1):\n",
    "    print(f\"  {i}. {row.feature} (coefficient: {row.coefficient:.4f})\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved Files:\")\n",
    "print(f\"  â€¢ Model: {model_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ LOGISTIC REGRESSION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# COMMAND ----------"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "logistic_regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
